# Module 4: Supervised Machine Learning - Part 2

This module covers more advanced supervised learning methods that include ensembles of trees (random forests, gradient boosted trees), and neural networks (with an optional summary on deep learning). You will also learn about the critical problem of data leakage in machine learning and how to detect and avoid it.

## Learning Objectives

- Understand how specific supervised learning algorithms - in particular, those based on decision trees and neural networks - estimate their own parameters from data to make new predictions.
- Apply the right algorithm for a given task by understanding the strengths and weaknesses of additional supervised learning methods.
- Apply additional types of supervised machine learning algorithms in Python with scikit-learn.
- Recognize and avoid instances of data leakage

## Module 4: Supervised Machine Learning - Part 2

- [Reading - Week 4 Slides](./Readings/04-adspy-module4-supervised2.pdf)

- [Lab - Supervised Learning, Part II](./Labs/Module%204.ipynb)

- [Video - Naive Bayes Classifiers](https://www.coursera.org/learn/python-machine-learning/lecture/0XFms/naive-bayes-classifiers)

- [Video - Random Forests](https://www.coursera.org/learn/python-machine-learning/lecture/lF9QN/random-forests)

- [Video - Gradient Boosted Decision Trees](https://www.coursera.org/learn/python-machine-learning/lecture/emwn3/gradient-boosted-decision-trees)

- [Video - Neural Networks](https://www.coursera.org/learn/python-machine-learning/lecture/v4cs3/neural-networks)

- [Reading - Neural Networks Made Easy (optional)](https://techcrunch.com/2017/04/13/neural-networks-made-easy/)

- [Reading - Play with Neural Networks: TensorFlow Playground (optional)](http://playground.tensorflow.org/)

- [Video - Deep Learning (Optional)](https://www.coursera.org/learn/python-machine-learning/lecture/oAXno/deep-learning-optional)

- [Reading - Deep Learning in a Nutshell: Core Concepts (optional)](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)

- [Reading - Assisting Pathologists in Detecting Cancer with Deep Learning (optional)](https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html)

- [Video - Data Leakage](https://www.coursera.org/learn/python-machine-learning/lecture/ois3n/data-leakage)

- [Reading - The Treachery of Leakage (optional)](https://medium.com/@colin.fraser/the-treachery-of-leakage-56a2d7c4e931)

- [Reading - Leakage in Data Mining: Formulation, Detection, and Avoidance (optional)](http://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf)

- [Reading - Data Leakage Example: The ICML 2013 Whale Challenge (optional)](https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865#25839#post25839)

- [Reading - Rules of Machine Learning: Best Practices for ML Engineering (optional)](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)

## Assignment 4

- [Lab - Understanding and Predicting Property Maintenance Fines](./Labs/Assignment%204.ipynb)

## Optional: Unsupervised Machine Learning

- [Reading - Unsupervised Machine Learning Slides](./Readings/05-adspy-unsupervised.pdf)

- [Lab - Unsupervised Learning](./Labs/Unsupervised%20Learning.ipynb)

- [Video - Introduction](https://www.coursera.org/learn/python-machine-learning/lecture/XIt7x/introduction)

- [Video - Dimensionality Reduction and Manifold Learning](https://www.coursera.org/learn/python-machine-learning/lecture/cgzXI/dimensionality-reduction-and-manifold-learning)

- [Video - Clustering](https://www.coursera.org/learn/python-machine-learning/lecture/Xs8IM/clustering)

- [Reading - How to Use t-SNE Effectively](http://distill.pub/2016/misread-tsne/)

- [Reading - How Machines Make Sense of Big Data: an Introduction to Clustering Algorithms](https://www.freecodecamp.org/news/how-machines-make-sense-of-big-data-an-introduction-to-clustering-algorithms-4bd97d4fbaba/)

## Conclusion

- [Video - Conclusion](https://www.coursera.org/learn/python-machine-learning/lecture/eRkjD/conclusion)